{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Building a Chatbot with history",
   "id": "14fa86abc76304f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:51.686855Z",
     "start_time": "2025-07-01T20:21:51.667224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"]=os.getenv(\"GEMINI_KEY\")\n",
    "#Langchain Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_KEY\")"
   ],
   "id": "6fd908b3d034b7a4",
   "outputs": [],
   "execution_count": 217
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:52.260818Z",
     "start_time": "2025-07-01T20:21:51.718096Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"gemma2-9b-it\")\n",
    "llm"
   ],
   "id": "efc1d6d83e26556f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000020B2940E780>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000020B2940EC40>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:52.884728Z",
     "start_time": "2025-07-01T20:21:52.290921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "response=llm.invoke([HumanMessage(content=\"Hii, My name is Sachin Goyal.I am currently pursuing my B.Tech(3rd year) from Thapar University in CSE,i am currently practising Generative Ai\")])\n",
    "response.content"
   ],
   "id": "9bf190b6b86af641",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Sachin,\\n\\nIt's great to meet you! \\n\\nPursuing a B.Tech in CSE from Thapar University is impressive, and it sounds like you're diving into a fascinating field with Generative AI. \\n\\nWhat aspects of Generative AI are you most interested in practicing? \\n\\nI'm always happy to chat about AI, whether it's about specific techniques, applications, or even the ethical considerations surrounding it. Feel free to ask me anything!\\n\""
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 219
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:53.469615Z",
     "start_time": "2025-07-01T20:21:52.903705Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hii, My name is Sachin Goyal.I am currently pursuing my B.Tech(3rd year) from Thapar University in CSE,i am currently practising Generative Ai.what will you suggest me for a better learning?\") ,\n",
    "        AIMessage(content=\"Hi Sachin,\\n\\nIt's great to meet you!  It's impressive that you're already practicing Generative AI during your B.Tech in CSE at Thapar University.  That's a very forward-looking skillset to be developing.  What specific areas of Generative AI are you focusing on right now?  I'd be interested to hear more about your projects.\") ,\n",
    "        HumanMessage(content=\"What is my name?\")\n",
    "    ]\n",
    ")\n"
   ],
   "id": "39d4e341599a6db5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Sachin Goyal.  I remember! 😊 \\n\\nIs there anything specific you'd like to learn more about regarding Generative AI?  We could discuss:\\n\\n* **Specific models:**  Like GPT-3, DALL-E 2, Stable Diffusion, etc.\\n* **Techniques:**  Such as diffusion models, transformer networks, GANs.\\n* **Applications:**  Like text generation, image creation, music composition, code generation.\\n* **Ethical considerations:**  Bias, fairness, misuse potential.\\n* **Resources for learning:**  Books, courses, online communities. \\n\\nLet me know what piques your interest!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 139, 'prompt_tokens': 152, 'total_tokens': 291, 'completion_time': 0.252727273, 'prompt_time': 0.006549447, 'queue_time': 0.24760658200000002, 'total_time': 0.25927672}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--6594ffc8-f562-4102-ae87-269e45229dd1-0', usage_metadata={'input_tokens': 152, 'output_tokens': 139, 'total_tokens': 291})"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 220
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:53.494202Z",
     "start_time": "2025-07-01T20:21:53.486710Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={} #storing all the chat with their id to uniquely define and prevent chat mixing\n",
    "def get_session_history(session_id)->BaseChatMessageHistory:\n",
    "    if session_id not in store:  #if new chat then store the chat going on\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_message_history=RunnableWithMessageHistory(llm,get_session_history)"
   ],
   "id": "f553e900ae2eb5e2",
   "outputs": [],
   "execution_count": 221
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:55.149475Z",
     "start_time": "2025-07-01T20:21:53.527817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#declaring session id chat1 for this chat for a user\n",
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response=with_message_history.invoke (\n",
    "    [ HumanMessage(content=\"Hii, My name is Sachin Goyal.I am currently pursuing my B.Tech(3rd year) from Thapar University in CSE,i am currently practising Generative Ai.what will you suggest me for a better learning?\") ]\n",
    "    ,config=config )\n",
    "response"
   ],
   "id": "eb3647b7e83c0cba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hey Sachin,\\n\\nIt\\'s awesome that you\\'re diving into the world of Generative AI during your B.Tech! That\\'s a super exciting field with tons of potential. \\n\\nSince you\\'re already practicing, let\\'s focus on boosting your learning even further. Here\\'s a breakdown of suggestions:\\n\\n**1. Deepen Your Foundations:**\\n\\n* **Machine Learning:** Generative AI heavily relies on ML concepts.  Make sure you have a strong grasp of:\\n    * Supervised vs. Unsupervised Learning\\n    * Regression vs. Classification\\n    * Common algorithms (Linear Regression, Decision Trees, SVMs, etc.)\\n    * Evaluation metrics (Accuracy, Precision, Recall, F1-Score)\\n* **Deep Learning:** Generative AI often uses deep neural networks. Familiarize yourself with:\\n    * Convolutional Neural Networks (CNNs) for image generation\\n    * Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks for text generation\\n    * Generative Adversarial Networks (GANs) - the cornerstone of many generative models\\n* **Probability and Statistics:** Understanding probability distributions, Bayesian inference, and statistical concepts is crucial for working with generative models.\\n\\n**2. Dive into Specific Generative Techniques:**\\n\\n* **GANs:**  Experiment with different GAN architectures (DCGAN, StyleGAN, WGAN) and explore techniques like image-to-image translation and text-to-image synthesis.\\n* **Variational Autoencoders (VAEs):** Learn how VAEs learn latent representations of data and generate new samples.\\n* **Transformer Networks:** Explore transformers like GPT-3 and its variants for text generation, translation, and other NLP tasks.\\n\\n**3. Hands-on Practice is Key:**\\n\\n* **Kaggle Competitions:**  Participate in generative AI competitions on Kaggle to gain practical experience and learn from others.\\n* **Open-Source Projects:** Contribute to open-source projects related to generative AI. This will expose you to real-world codebases and collaboration.\\n* **Personal Projects:**  Build your own generative AI projects! This could involve:\\n    * Generating images in a specific style\\n    * Creating realistic text dialogue\\n    * Composing music\\n    * Designing new game levels\\n\\n**4. Stay Updated:**\\n\\n* **Research Papers:**  Follow the latest research papers in generative AI. ArXiv is a great resource.\\n* **Conferences and Workshops:** Attend conferences and workshops to network with experts and learn about cutting-edge advancements.\\n* **Online Communities:** Join online communities (e.g., Reddit\\'s r/MachineLearning, Discord servers) to discuss ideas, ask questions, and share your work.\\n\\n**Resources:**\\n\\n* **Books:**\\n    * \"Generative Deep Learning\" by David Foster\\n    * \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\\n* **Online Courses:**\\n    * Coursera:  \"Deep Learning Specialization\" by Andrew Ng\\n    * fast.ai: \"Practical Deep Learning for Coders\"\\n    * Udacity: \"Intro to Generative Adversarial Networks\" \\n* **Libraries & Tools:**\\n    * TensorFlow\\n    * PyTorch\\n    * Keras\\n    * Hugging Face Transformers\\n\\n\\nRemember, learning generative AI is a continuous journey. Be patient, persistent, and enjoy the process of discovery!\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 713, 'prompt_tokens': 56, 'total_tokens': 769, 'completion_time': 1.296363636, 'prompt_time': 0.003285158, 'queue_time': 0.248535322, 'total_time': 1.2996487939999999}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--46895a36-bcc8-4b2b-8a47-468a68d53f6c-0', usage_metadata={'input_tokens': 56, 'output_tokens': 713, 'total_tokens': 769})"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 222
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:55.575276Z",
     "start_time": "2025-07-01T20:21:55.189200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#see this time it says i don't know about you name\n",
    "#basically the session id is a new one so no previous chat available it will be stored for the first time\n",
    "\n",
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],config=config\n",
    ")\n",
    "response"
   ],
   "id": "444ad6763fc803b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to know!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 13, 'total_tokens': 50, 'completion_time': 0.067272727, 'prompt_time': 0.001834105, 'queue_time': 0.25129953400000005, 'total_time': 0.069106832}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--1d0c0c48-8e8c-4d8c-ae03-08de56114d0e-0', usage_metadata={'input_tokens': 13, 'output_tokens': 37, 'total_tokens': 50})"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 223
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:55.951590Z",
     "start_time": "2025-07-01T20:21:55.583306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"ok tell me what is my name\")],config=config\n",
    ")\n",
    "response\n",
    "#see it remembers my name"
   ],
   "id": "11bc2d67546fc965",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Sachin Goyal. 😊 \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 784, 'total_tokens': 797, 'completion_time': 0.023636364, 'prompt_time': 0.026718501, 'queue_time': 0.2492606, 'total_time': 0.050354865}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--be935fe9-866e-4247-a8ef-fbf4aae877ac-0', usage_metadata={'input_tokens': 784, 'output_tokens': 13, 'total_tokens': 797})"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:56.334030Z",
     "start_time": "2025-07-01T20:21:55.975687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke([HumanMessage(content=\"My name is John\")],config=config)\n",
    "response"
   ],
   "id": "1fc4d4421a8fe1ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi John! It's nice to meet you. 😊\\n\\nHow can I help you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 62, 'total_tokens': 85, 'completion_time': 0.041818182, 'prompt_time': 0.003502289, 'queue_time': 0.25167511200000003, 'total_time': 0.045320471}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--af940eb7-76f0-4138-bba2-3f49204f499c-0', usage_metadata={'input_tokens': 62, 'output_tokens': 23, 'total_tokens': 85})"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 225
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:56.723751Z",
     "start_time": "2025-07-01T20:21:56.357370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],config=config\n",
    ")\n",
    "response\n",
    "#this time remembers the name"
   ],
   "id": "e963eac8f340490e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is John, you told me earlier!  😄  \\n\\nIs there anything else I can help you with, John?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 97, 'total_tokens': 126, 'completion_time': 0.052727273, 'prompt_time': 0.004176181, 'queue_time': 0.247585548, 'total_time': 0.056903454}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--43bf4b27-81b9-4144-9e2e-3a4d8704453b-0', usage_metadata={'input_tokens': 97, 'output_tokens': 29, 'total_tokens': 126})"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 226
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ],
   "id": "a9058ecd2efa6306"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:56.749435Z",
     "start_time": "2025-07-01T20:21:56.742957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "         (\"system\",\"You are a helpful assistant ,communicate with the user according\"),\n",
    "         MessagesPlaceholder(variable_name=\"messages\")\n",
    "     ]\n",
    " )\n",
    "chain=prompt|llm"
   ],
   "id": "58a08cfe4b5b62ed",
   "outputs": [],
   "execution_count": 227
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:57.179279Z",
     "start_time": "2025-07-01T20:21:56.815028Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({\"messages\":[HumanMessage(content=\"Hii ,My name is Sachin Goyal\")]})",
   "id": "966015b1490ad42a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Sachin Goyal,\\n\\nIt's nice to meet you! How can I help you today? 😊  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 28, 'total_tokens': 54, 'completion_time': 0.047272727, 'prompt_time': 0.002085065, 'queue_time': 0.246472886, 'total_time': 0.049357792}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--35a20333-7398-45a6-bb7d-b71078073a13-0', usage_metadata={'input_tokens': 28, 'output_tokens': 26, 'total_tokens': 54})"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 228
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:57.203198Z",
     "start_time": "2025-07-01T20:21:57.198932Z"
    }
   },
   "cell_type": "code",
   "source": "with_message_history=RunnableWithMessageHistory(chain,get_session_history)",
   "id": "c056b993b7602bac",
   "outputs": [],
   "execution_count": 229
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:57.650786Z",
     "start_time": "2025-07-01T20:21:57.245711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'message':[HumanMessage(content=\"My name is Sachin Goyal\")]},config=config\n",
    ")\n",
    "response"
   ],
   "id": "820708e8c6e9de60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I know! You told me at the beginning.  \\n\\nIt's nice to meet you, Sachin. How can I help you further today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 821, 'total_tokens': 854, 'completion_time': 0.06, 'prompt_time': 0.028214673, 'queue_time': 0.250391636, 'total_time': 0.088214673}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--425f38b8-0667-4f8c-8536-b8c9d7a1abd9-0', usage_metadata={'input_tokens': 821, 'output_tokens': 33, 'total_tokens': 854})"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 230
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:58.169349Z",
     "start_time": "2025-07-01T20:21:57.671918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'message':[HumanMessage(content=\"can you tell me what is my age and my fav hobby\")]},config=config\n",
    ")\n",
    "response"
   ],
   "id": "28b6a5cfc84f1ea5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='As an AI, I don\\'t have access to personal information about you like your age or favorite hobby. \\n\\nTo tell me about yourself, you can simply say:\\n\\n* \"I\\'m 20 years old.\"\\n* \"My favorite hobby is playing basketball.\" \\n\\nI\\'m here to learn more about you! 😄  \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 75, 'prompt_tokens': 874, 'total_tokens': 949, 'completion_time': 0.136363636, 'prompt_time': 0.029559817, 'queue_time': 0.250290624, 'total_time': 0.165923453}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--50f358d9-0f7e-41b1-9b3e-736f8633240d-0', usage_metadata={'input_tokens': 874, 'output_tokens': 75, 'total_tokens': 949})"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 231
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "What if we have multiple inputs to be taken in prompt\n",
    "--> then there is a change in with_message_history\n",
    "    we need to define a correct key to use to save chat to history"
   ],
   "id": "4007295494d07960"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:58.193590Z",
     "start_time": "2025-07-01T20:21:58.188472Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "         (\"system\",\"You are a helpful assistant ,communicate with the user according in {language}\"),\n",
    "         MessagesPlaceholder(variable_name=\"messages\")\n",
    "     ]\n",
    " )\n",
    "chain=prompt|llm"
   ],
   "id": "15d1ce71bfe7fd48",
   "outputs": [],
   "execution_count": 232
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:58.615506Z",
     "start_time": "2025-07-01T20:21:58.235797Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({\"messages\":[HumanMessage(content=\"Hii ,My name is Sachin Goyal\")],\"language\":\"Hindi\"})",
   "id": "db736d7109c1b121",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते Sachin Goyal! 😊  मैं आपकी मदद करने के लिए तैयार हूँ। आप मुझसे क्या पूछना चाहेंगे? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 30, 'total_tokens': 67, 'completion_time': 0.067272727, 'prompt_time': 0.002072055, 'queue_time': 0.246827655, 'total_time': 0.069344782}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--d1315437-a7bd-4180-bec1-77be55ea44d9-0', usage_metadata={'input_tokens': 30, 'output_tokens': 37, 'total_tokens': 67})"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 233
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:21:58.661381Z",
     "start_time": "2025-07-01T20:21:58.656471Z"
    }
   },
   "cell_type": "code",
   "source": "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")",
   "id": "2ac3141b7d665bc3",
   "outputs": [],
   "execution_count": 234
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "whenever we reuse the older session for ex chat1 then it loads the old history and as we used english by default so now declaring any other language may not work for that and will print in english",
   "id": "d66878c48bff0549"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:24:18.568769Z",
     "start_time": "2025-07-01T20:24:18.094396Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"can you tell me my name \")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "afef132f1e4c31e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Sachin Goyal.  \\n\\nIs there anything else I can help you with today? 🤔  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 996, 'total_tokens': 1021, 'completion_time': 0.045454545, 'prompt_time': 0.033659675, 'queue_time': 0.251460365, 'total_time': 0.07911422}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--c74f3553-a440-486d-9b95-284757d442bd-0', usage_metadata={'input_tokens': 996, 'output_tokens': 25, 'total_tokens': 1021})"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 239
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:24:49.118386Z",
     "start_time": "2025-07-01T20:24:48.635494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"My name is Sachin Goyal\")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "996adf0a8342f763",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते, Sachin Goyal!  \\n\\nमुझे बहुत अच्छा लगा आपका नाम जानकर।  आपसे बातचीत करना मेरे लिए खुशी की बात है। 😊 \\n\\nक्या मैं आपकी कोई और मदद कर सकता हूँ?  \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 149, 'total_tokens': 207, 'completion_time': 0.105454545, 'prompt_time': 0.006966222, 'queue_time': 0.24923800799999998, 'total_time': 0.112420767}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--497a6b01-4c5e-44c3-afd8-e6df2a6f881c-0', usage_metadata={'input_tokens': 149, 'output_tokens': 58, 'total_tokens': 207})"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-01T20:25:05.130804Z",
     "start_time": "2025-07-01T20:25:04.674735Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"can you tell me my name \")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "bf5016f7dd752ae4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='तुम्हारा नाम Sachin Goyal है! \\n\\nक्या मैं तुम्हें और कुछ बता सकता हूँ? 😊 \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 221, 'total_tokens': 251, 'completion_time': 0.054545455, 'prompt_time': 0.010196478, 'queue_time': 0.247837231, 'total_time': 0.064741933}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ec27a406-57f7-40d1-acad-4d7eac9f311e-0', usage_metadata={'input_tokens': 221, 'output_tokens': 30, 'total_tokens': 251})"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 242
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
