{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Building a Chatbot with history",
   "id": "14fa86abc76304f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:44.943025Z",
     "start_time": "2025-07-04T08:42:44.905253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"]=os.getenv(\"GEMINI_KEY\")\n",
    "#Langchain Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_KEY\")"
   ],
   "id": "6fd908b3d034b7a4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:47.544762Z",
     "start_time": "2025-07-04T08:42:44.956861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"gemma2-9b-it\")\n",
    "llm"
   ],
   "id": "efc1d6d83e26556f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000019917A60050>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019917A60D70>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:48.754325Z",
     "start_time": "2025-07-04T08:42:47.572010Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "response=llm.invoke([HumanMessage(content=\"Hii, My name is Sachin Goyal.I am currently pursuing my B.Tech(3rd year) from Thapar University in CSE,i am currently practising Generative Ai\")])\n",
    "response.content"
   ],
   "id": "9bf190b6b86af641",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Sachin,\\n\\nIt's great to meet you! It's impressive that you're already practicing Generative AI in your third year of B.Tech at Thapar University. \\n\\nThat's a cutting-edge field with a lot of potential.\\n\\nWhat specific areas of Generative AI are you focusing on? Are you working on any particular projects? I'd love to hear more about your work!\\n\\nI can also offer some information or resources if you have any questions about Generative AI.\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:49.157660Z",
     "start_time": "2025-07-04T08:42:48.770776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hii, My name is Sachin Goyal.I am currently pursuing my B.Tech(3rd year) from Thapar University in CSE,i am currently practising Generative Ai.what will you suggest me for a better learning?\") ,\n",
    "        AIMessage(content=\"Hi Sachin,\\n\\nIt's great to meet you!  It's impressive that you're already practicing Generative AI during your B.Tech in CSE at Thapar University.  That's a very forward-looking skillset to be developing.  What specific areas of Generative AI are you focusing on right now?  I'd be interested to hear more about your projects.\") ,\n",
    "        HumanMessage(content=\"What is my name?\")\n",
    "    ]\n",
    ")\n"
   ],
   "id": "39d4e341599a6db5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Sachin Goyal. 😊  \\n\\nI remember that from our first interaction!  Is there anything else I can help you with today?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 152, 'total_tokens': 185, 'completion_time': 0.06, 'prompt_time': 0.006521219, 'queue_time': 0.243865931, 'total_time': 0.066521219}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--d40138d8-c4a8-4982-a9c8-ebc1feb4c0f1-0', usage_metadata={'input_tokens': 152, 'output_tokens': 33, 'total_tokens': 185})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:49.219576Z",
     "start_time": "2025-07-04T08:42:49.184041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={} #storing all the chat with their id to uniquely define and prevent chat mixing\n",
    "def get_session_history(session_id)->BaseChatMessageHistory:\n",
    "    if session_id not in store:  #if new chat then store the chat going on\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_message_history=RunnableWithMessageHistory(llm,get_session_history)"
   ],
   "id": "f553e900ae2eb5e2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:51.713367Z",
     "start_time": "2025-07-04T08:42:49.255117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#declaring session id chat1 for this chat for a user\n",
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response=with_message_history.invoke (\n",
    "    [ HumanMessage(content=\"Hii, My name is Sachin Goyal.I am currently pursuing my B.Tech(3rd year) from Thapar University in CSE,i am currently practising Generative Ai.what will you suggest me for a better learning?\") ]\n",
    "    ,config=config )\n",
    "response"
   ],
   "id": "eb3647b7e83c0cba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hey Sachin, it's great to hear you're diving into the exciting world of Generative AI! As a large language model myself, I'm happy to offer some suggestions for your learning journey. \\n\\nSince you're already in your 3rd year of a B.Tech in CSE at Thapar University, you have a strong foundation. Here's a structured approach to enhance your Generative AI skills:\\n\\n**1. Solidify Your Fundamentals:**\\n\\n* **Deep Learning:** Ensure you have a solid grasp of deep learning concepts:\\n    * **Neural Networks:** Architectures (CNNs, RNNs, Transformers), activation functions, backpropagation, optimization algorithms.\\n    * **Machine Learning:** Supervised, unsupervised, and reinforcement learning.\\n    * **Python & Libraries:**  Master Python and essential libraries like TensorFlow, PyTorch, Keras.\\n\\n* **Mathematics:**  Brush up on linear algebra, calculus, and probability/statistics – they are crucial for understanding deep learning algorithms.\\n\\n**2. Dive into Generative Models:**\\n\\n* **Generative Adversarial Networks (GANs):**  Understand the core concepts of GANs (generator, discriminator, loss functions).\\n    * Explore different GAN architectures (DCGAN, StyleGAN, CycleGAN).\\n* **Variational Autoencoders (VAEs):** Learn how VAEs work and their applications in generating data.\\n* **Transformer-based Models:**  Familiarize yourself with the Transformer architecture (e.g., GPT, T5, BERT) and their role in text generation.\\n\\n**3. Hands-on Experience:**\\n\\n* **Projects:** The best way to learn is by doing! \\n    * Work on projects that involve generating images, text, audio, or other types of data. \\n    * Kaggle competitions are a great source of datasets and challenges.\\n* **Code Examples & Tutorials:**  \\n    * Follow tutorials and explore code examples from reputable sources (e.g., TensorFlow tutorials, PyTorch documentation, OpenAI blog).\\n* **Experiment:** Don't be afraid to experiment with different architectures, hyperparameters, and datasets.\\n\\n**4.  Stay Up-to-Date:**\\n\\n* **Research Papers:**  Keep abreast of the latest advancements in Generative AI by reading research papers.\\n* **Conferences & Workshops:** Attend conferences and workshops to network with experts and learn about cutting-edge research.\\n* **Online Communities:** Join online communities (e.g., Reddit's r/MachineLearning, Discord servers) to discuss ideas, ask questions, and share your work.\\n\\n**Resources:**\\n\\n* **Coursera & edX:**  Offer courses on deep learning and Generative AI.\\n* **DeepLearning.AI:** Specializes in deep learning education.\\n* **OpenAI:** Provides access to powerful AI models and resources.\\n* **Hugging Face:** A platform for sharing and accessing pre-trained AI models.\\n\\n**Remember:**\\n\\n* **Be patient and persistent:** Learning Generative AI takes time and effort. Don't get discouraged if you encounter challenges.\\n* **Focus on understanding:**  Don't just memorize code; strive to understand the underlying concepts.\\n* **Have fun!** Generative AI is a fascinating field with endless possibilities.\\n\\nGood luck with your learning journey, Sachin! Let me know if you have any more questions.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 705, 'prompt_tokens': 56, 'total_tokens': 761, 'completion_time': 1.2818181819999999, 'prompt_time': 0.00327487, 'queue_time': 0.24323509899999998, 'total_time': 1.2850930520000001}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--17876a0a-ebbc-4d72-afce-4769a888779a-0', usage_metadata={'input_tokens': 56, 'output_tokens': 705, 'total_tokens': 761})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:52.138193Z",
     "start_time": "2025-07-04T08:42:51.731822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#see this time it says i don't know about you name\n",
    "#basically the session id is a new one so no previous chat available it will be stored for the first time\n",
    "\n",
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],config=config\n",
    ")\n",
    "response"
   ],
   "id": "444ad6763fc803b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me your name, I'd be happy to use it! 😊\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 13, 'total_tokens': 55, 'completion_time': 0.076363636, 'prompt_time': 0.00184683, 'queue_time': 0.244350179, 'total_time': 0.078210466}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--b36d84c7-0493-41f2-9623-49b650b03136-0', usage_metadata={'input_tokens': 13, 'output_tokens': 42, 'total_tokens': 55})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:52.598716Z",
     "start_time": "2025-07-04T08:42:52.181191Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"ok tell me what is my name\")],config=config\n",
    ")\n",
    "response\n",
    "#see it remembers my name"
   ],
   "id": "11bc2d67546fc965",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Sachin Goyal.  😊\\n\\nIt's nice to meet you, Sachin! \\n\\nDo you have any other questions for me? Perhaps about Generative AI?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 776, 'total_tokens': 816, 'completion_time': 0.072727273, 'prompt_time': 0.032538779, 'queue_time': 0.24680955000000002, 'total_time': 0.105266052}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--e34cd2a3-0aa6-4671-8992-e68956bc53eb-0', usage_metadata={'input_tokens': 776, 'output_tokens': 40, 'total_tokens': 816})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:53.011402Z",
     "start_time": "2025-07-04T08:42:52.645993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke([HumanMessage(content=\"My name is John\")],config=config)\n",
    "response"
   ],
   "id": "1fc4d4421a8fe1ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi John! It's nice to meet you. What can I do for you today? 😊  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 67, 'total_tokens': 92, 'completion_time': 0.045454545, 'prompt_time': 0.0035126, 'queue_time': 0.24696273900000001, 'total_time': 0.048967145}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--4df9bfa1-7df4-4a5c-a535-838f56da5d41-0', usage_metadata={'input_tokens': 67, 'output_tokens': 25, 'total_tokens': 92})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:53.390097Z",
     "start_time": "2025-07-04T08:42:53.032125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],config=config\n",
    ")\n",
    "response\n",
    "#this time remembers the name"
   ],
   "id": "e963eac8f340490e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is John.  I remember! 😊  Anything else I can help you with?  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 103, 'total_tokens': 126, 'completion_time': 0.041818182, 'prompt_time': 0.00491438, 'queue_time': 0.2457163, 'total_time': 0.046732562}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--50d7ee90-e7bd-4cf1-933f-6ef16cae1d6a-0', usage_metadata={'input_tokens': 103, 'output_tokens': 23, 'total_tokens': 126})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages.\n",
    "\n",
    "\n",
    "HOW IT WORKS\n",
    "\n",
    "-->we create a prompt where system command is there to llm\n",
    "\n",
    "-->we create a variable of MessagePlaceholder which will place all the previous msg+new one\n",
    "\n",
    "-->we create a chain of prompt and llm\n",
    "\n",
    "-->for chat history we have Runnable with msgHistory which gets session id and\n",
    "    retrieve all the prev msg history and provide it to chain\n",
    "\n",
    "-->the llm will generate the response based on the prev history"
   ],
   "id": "a9058ecd2efa6306"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:46:38.920683Z",
     "start_time": "2025-07-04T08:46:38.889227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "         (\"system\",\"You are a helpful assistant ,communicate with the user according\"),\n",
    "         MessagesPlaceholder(variable_name=\"messages\")\n",
    "     ]\n",
    " )\n",
    "chain=prompt|llm"
   ],
   "id": "58a08cfe4b5b62ed",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:46:41.040415Z",
     "start_time": "2025-07-04T08:46:40.548136Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({\"messages\":[HumanMessage(content=\"Hii ,My name is Sachin Goyal\")]})",
   "id": "966015b1490ad42a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Sachin Goyal, \\n\\nIt's nice to meet you! 👋\\n\\nHow can I help you today? 😊 \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 28, 'total_tokens': 57, 'completion_time': 0.052727273, 'prompt_time': 0.00206893, 'queue_time': 0.24470646000000001, 'total_time': 0.054796203}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--cca8e2e3-dca9-4474-9467-8309fb70f8ce-0', usage_metadata={'input_tokens': 28, 'output_tokens': 29, 'total_tokens': 57})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:46:43.647707Z",
     "start_time": "2025-07-04T08:46:43.642124Z"
    }
   },
   "cell_type": "code",
   "source": "with_message_history=RunnableWithMessageHistory(chain,get_session_history)",
   "id": "c056b993b7602bac",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:46:49.727793Z",
     "start_time": "2025-07-04T08:46:49.221269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'message':[HumanMessage(content=\"My name is Sachin Goyal\")]},config=config\n",
    ")\n",
    "response"
   ],
   "id": "820708e8c6e9de60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Sachin Goyal! \\n\\nIt's nice to officially meet you.  \\n\\nHow can I help you explore the world of Generative AI today? \\n\\n\\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 1063, 'total_tokens': 1100, 'completion_time': 0.067272727, 'prompt_time': 0.036000428, 'queue_time': 0.249809101, 'total_time': 0.103273155}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--6b372dec-a552-45b1-a9d3-2a455691d089-0', usage_metadata={'input_tokens': 1063, 'output_tokens': 37, 'total_tokens': 1100})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:47:18.824570Z",
     "start_time": "2025-07-04T08:47:18.277167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'message':[HumanMessage(content=\"can you tell me what is my name,age and my fav hobby\")]},config=config\n",
    ")\n",
    "response"
   ],
   "id": "28b6a5cfc84f1ea5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have access to personal information about you like your age or favorite hobby.  \\n\\nI do know your name is Sachin Goyal, though! \\n\\nWould you like to tell me about your favorite hobby? I'm always eager to learn new things. 😊 \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 64, 'prompt_tokens': 1244, 'total_tokens': 1308, 'completion_time': 0.116363636, 'prompt_time': 0.048218107, 'queue_time': 0.256127273, 'total_time': 0.164581743}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--1eedd660-0108-43fd-b3fb-7887b19644ec-0', usage_metadata={'input_tokens': 1244, 'output_tokens': 64, 'total_tokens': 1308})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "What if we have multiple inputs to be taken in prompt\n",
    "--> then there is a change in with_message_history\n",
    "    we need to define a correct key to use to save chat to history"
   ],
   "id": "4007295494d07960"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:55.128270Z",
     "start_time": "2025-07-04T08:42:55.123563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "         (\"system\",\"You are a helpful assistant ,communicate with the user according in {language}\"),\n",
    "         MessagesPlaceholder(variable_name=\"messages\")\n",
    "     ]\n",
    " )\n",
    "chain=prompt|llm"
   ],
   "id": "15d1ce71bfe7fd48",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:55.613797Z",
     "start_time": "2025-07-04T08:42:55.196950Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({\"messages\":[HumanMessage(content=\"Hii ,My name is Sachin Goyal\")],\"language\":\"Hindi\"})",
   "id": "db736d7109c1b121",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते सचिन गोयल जी! 👋 \\n\\nमैं आपकी मदद करने के लिए यहाँ हूँ।  आप क्या पूछना चाहेंगे? \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 30, 'total_tokens': 73, 'completion_time': 0.078181818, 'prompt_time': 0.002842749, 'queue_time': 0.265423542, 'total_time': 0.081024567}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--c263061b-4f75-4564-99bf-f7724e639075-0', usage_metadata={'input_tokens': 30, 'output_tokens': 43, 'total_tokens': 73})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:55.639761Z",
     "start_time": "2025-07-04T08:42:55.633588Z"
    }
   },
   "cell_type": "code",
   "source": "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")",
   "id": "2ac3141b7d665bc3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "whenever we reuse the older session for ex chat1 then it loads the old history and as we used english by default so now declaring any other language may not work for that and will print in english",
   "id": "d66878c48bff0549"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:56.157181Z",
     "start_time": "2025-07-04T08:42:55.694176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"can you tell me my name \")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "afef132f1e4c31e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You said your name is Sachin Goyal.  \\n\\nIs there anything else I can help you with regarding Generative AI? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 1022, 'total_tokens': 1051, 'completion_time': 0.052727273, 'prompt_time': 0.083615019, 'queue_time': 0.24546717099999998, 'total_time': 0.136342292}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--4c978b49-57fb-4ee7-bb9e-0407c4277540-0', usage_metadata={'input_tokens': 1022, 'output_tokens': 29, 'total_tokens': 1051})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:56.602602Z",
     "start_time": "2025-07-04T08:42:56.178187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"My name is Sachin Goyal\")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "996adf0a8342f763",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='नमस्ते Sachin Goyal! \\n\\nमुझे आपसे बात करने में खुशी हो रही है। \\n\\nआप क्या पूछना चाहते हैं? मैं आपकी मदद करने के लिए तैयार हूँ।  😊\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 28, 'total_tokens': 78, 'completion_time': 0.090909091, 'prompt_time': 0.00207719, 'queue_time': 0.2438898, 'total_time': 0.092986281}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--660c16cf-c1e5-47f5-bf88-54607de5c935-0', usage_metadata={'input_tokens': 28, 'output_tokens': 50, 'total_tokens': 78})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:42:57.001138Z",
     "start_time": "2025-07-04T08:42:56.628200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"can you tell me my name \")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "bf5016f7dd752ae4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='बिल्कुल! आपका नाम **Sachin Goyal** है। \\n\\nक्या कुछ और बताना चाहेंगे? 😉\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 93, 'total_tokens': 123, 'completion_time': 0.054545455, 'prompt_time': 0.004160551, 'queue_time': 0.247050908, 'total_time': 0.058706006}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--148aa70f-09c9-4325-8ef9-bd7ab47f8e1c-0', usage_metadata={'input_tokens': 93, 'output_tokens': 30, 'total_tokens': 123})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Managing the Conversation History\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ],
   "id": "d91b0035c94c2dbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T09:05:33.116500Z",
     "start_time": "2025-07-04T09:05:32.984584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy='last', # keep the msgs from last with tokens<=max_tokens\n",
    "    token_counter=llm,\n",
    "    allow_partial=False, #If a msg pushes total tokens over 45, it won’t partially include it instead, it will stop adding messages.\n",
    "    include_system=True, # as system guides the model what should it do so it must be present anyhow even after trimming msgs\n",
    "    start_on='human'  #look for the most recent HumanMessage and start including from there.\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ],
   "id": "bfd75dc6c1b11809",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "maybe the trimmer trimmed the ice cream part here so not working check next code section",
   "id": "ddd23d7b6dbea649"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:56:28.797369Z",
     "start_time": "2025-07-04T08:56:28.342871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(\n",
    "        RunnablePassthrough.assign(messages=itemgetter(\"messages\") |trimmer)\n",
    "       | prompt\n",
    "       | llm\n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\"messages\":messages+[HumanMessage(content=\"what ice cream do i like\")],\"language\":\"Hindi\"}\n",
    ")\n",
    "response"
   ],
   "id": "ad48d85361c6942d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As a helpful assistant, I don't have access to your personal preferences like your favorite ice cream flavor. \\n\\nWhat's your favorite ice cream?  🍦😋\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 79, 'total_tokens': 117, 'completion_time': 0.069090909, 'prompt_time': 0.00382009, 'queue_time': 0.24639867999999998, 'total_time': 0.072910999}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--f7d749dd-0e1c-48bb-9848-c9177349a531-0', usage_metadata={'input_tokens': 79, 'output_tokens': 38, 'total_tokens': 117})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:55:55.068630Z",
     "start_time": "2025-07-04T08:55:54.376247Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(\n",
    "        RunnablePassthrough.assign(messages=itemgetter(\"messages\") |trimmer)\n",
    "       | prompt\n",
    "       | llm\n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\"messages\":messages+[HumanMessage(content=\"what was my question regarding maths\")],\"language\":\"Hindi\"}\n",
    ")\n",
    "response"
   ],
   "id": "d65a7b8d2157dfe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You asked \"what\\'s 2 + 2?\" 😊  \\n\\n\\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 79, 'total_tokens': 107, 'completion_time': 0.050909091, 'prompt_time': 0.00374958, 'queue_time': 0.24602295, 'total_time': 0.054658671}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--40840605-7a2e-4e23-9ea6-2317a375bf97-0', usage_metadata={'input_tokens': 79, 'output_tokens': 28, 'total_tokens': 107})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wrapping with Message history (summary only)\n",
   "id": "89bcb3d1f05ae272"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:43:39.267638Z",
     "start_time": "2025-07-04T08:43:39.262054Z"
    }
   },
   "cell_type": "code",
   "source": "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")",
   "id": "11ded0d3835f1412",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:43:39.741234Z",
     "start_time": "2025-07-04T08:43:39.291727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat6\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":messages+[HumanMessage(content=\"what is my name\")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "7c80d5d8804c3eef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='मैं आपको कुछ भी नहीं जानता! \\n\\nमैं एक बड़ा भाषा मॉडल हूँ, इसलिए मुझे याद नहीं रहता कि हमने पहले क्या बात की थी या आपका नाम क्या है।  \\n\\nक्या आप मुझे बताना चाहेंगे? 😊\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 79, 'total_tokens': 139, 'completion_time': 0.109090909, 'prompt_time': 0.00392919, 'queue_time': 0.243353689, 'total_time': 0.113020099}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--488684ee-88d2-4ebe-8067-e1e13060ce26-0', usage_metadata={'input_tokens': 79, 'output_tokens': 60, 'total_tokens': 139})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T08:43:40.198636Z",
     "start_time": "2025-07-04T08:43:39.766988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat6\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":messages+[HumanMessage(content=\"My name is Sachin,can you tell me the meaning of this \")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "727940c11440c2b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sachin नाम का अर्थ \"सफलता\" या \"विजय\" होता है। यह एक बहुत ही सुन्दर और प्रसिद्ध नाम है। \\n\\nक्या आप कोई और जानकारी चाहते हैं? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 72, 'total_tokens': 118, 'completion_time': 0.083636364, 'prompt_time': 0.00376628, 'queue_time': 0.24513489, 'total_time': 0.087402644}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--86410241-3ebb-413b-a363-d40907569a0a-0', usage_metadata={'input_tokens': 72, 'output_tokens': 46, 'total_tokens': 118})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
