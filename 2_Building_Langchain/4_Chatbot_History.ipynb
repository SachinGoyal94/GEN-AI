{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Building a Chatbot with history",
   "id": "14fa86abc76304f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:33:53.599596Z",
     "start_time": "2025-07-02T12:33:53.558718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"]=os.getenv(\"GEMINI_KEY\")\n",
    "#Langchain Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_KEY\")"
   ],
   "id": "6fd908b3d034b7a4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:33:56.151166Z",
     "start_time": "2025-07-02T12:33:53.624482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"gemma2-9b-it\")\n",
    "llm"
   ],
   "id": "efc1d6d83e26556f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001AF849B0440>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001AF849B1010>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:33:57.047725Z",
     "start_time": "2025-07-02T12:33:56.175222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "response=llm.invoke([HumanMessage(content=\"Hii, My name is Sachin Goyal.I am currently pursuing my B.Tech(3rd year) from Thapar University in CSE,i am currently practising Generative Ai\")])\n",
    "response.content"
   ],
   "id": "9bf190b6b86af641",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey Sachin,\\n\\nThat's awesome! It's great to meet another aspiring AI enthusiast. \\n\\nThapar University's CSE program is known to be quite strong, so you're in a good spot to learn and grow.  \\n\\nPracticing Generative AI is really exciting - what specific areas within Generative AI are you focusing on? Are you working on text generation, image synthesis, or something else entirely? \\n\\nI'm always eager to learn about what others are working on. Maybe we can even bounce some ideas off each other sometime!\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:33:57.527252Z",
     "start_time": "2025-07-02T12:33:57.075940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "llm.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hii, My name is Sachin Goyal.I am currently pursuing my B.Tech(3rd year) from Thapar University in CSE,i am currently practising Generative Ai.what will you suggest me for a better learning?\") ,\n",
    "        AIMessage(content=\"Hi Sachin,\\n\\nIt's great to meet you!  It's impressive that you're already practicing Generative AI during your B.Tech in CSE at Thapar University.  That's a very forward-looking skillset to be developing.  What specific areas of Generative AI are you focusing on right now?  I'd be interested to hear more about your projects.\") ,\n",
    "        HumanMessage(content=\"What is my name?\")\n",
    "    ]\n",
    ")\n"
   ],
   "id": "39d4e341599a6db5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Sachin Goyal. üòä  \\n\\nI remembered that from our first interaction! \\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 152, 'total_tokens': 175, 'completion_time': 0.041818182, 'prompt_time': 0.01006478, 'queue_time': 0.24592119899999998, 'total_time': 0.051882962}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--008607b4-68f7-49c3-aeec-38bec7000166-0', usage_metadata={'input_tokens': 152, 'output_tokens': 23, 'total_tokens': 175})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:33:57.593944Z",
     "start_time": "2025-07-02T12:33:57.538233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={} #storing all the chat with their id to uniquely define and prevent chat mixing\n",
    "def get_session_history(session_id)->BaseChatMessageHistory:\n",
    "    if session_id not in store:  #if new chat then store the chat going on\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "with_message_history=RunnableWithMessageHistory(llm,get_session_history)"
   ],
   "id": "f553e900ae2eb5e2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:33:59.992369Z",
     "start_time": "2025-07-02T12:33:57.636034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#declaring session id chat1 for this chat for a user\n",
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "\n",
    "response=with_message_history.invoke (\n",
    "    [ HumanMessage(content=\"Hii, My name is Sachin Goyal.I am currently pursuing my B.Tech(3rd year) from Thapar University in CSE,i am currently practising Generative Ai.what will you suggest me for a better learning?\") ]\n",
    "    ,config=config )\n",
    "response"
   ],
   "id": "eb3647b7e83c0cba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's awesome, Sachin! It's great to hear you're diving into the exciting world of Generative AI during your B.Tech.  \\n\\nHere are some suggestions to level up your learning:\\n\\n**Deepen Your Foundations:**\\n\\n* **Machine Learning Fundamentals:**  Ensure you have a solid grasp of core ML concepts like supervised/unsupervised learning, deep learning architectures (CNNs, RNNs, Transformers), and common algorithms. There are fantastic online courses on platforms like Coursera, edX, and fast.ai.\\n* **Python Proficiency:** Python is the go-to language for AI.  Master its libraries like NumPy, Pandas, Matplotlib, and TensorFlow/PyTorch.  \\n\\n**Dive into Generative AI Specifically:**\\n\\n* **Text Generation:** Explore models like GPT-3, BERT, T5, and their open-source counterparts (e.g., GPT-Neo, Bloom). Understand how they work and experiment with fine-tuning them for specific tasks like story writing, dialogue generation, or code completion.\\n* **Image Generation:**  Familiarize yourself with GANs (Generative Adversarial Networks), Diffusion Models (e.g., DALL-E 2, Stable Diffusion), and VAEs (Variational Autoencoders).  \\n\\n**Practical Projects:**\\n\\n* **Build Your Own Models:**  Don't just read about it! Start with simple text generation tasks and gradually work your way up to more complex projects like creating image variations or generating music.\\n* **Kaggle Competitions:** Participate in AI-focused competitions on Kaggle. They provide real-world datasets and challenges to test your skills.\\n* **Open-Source Contributions:** Contribute to open-source generative AI projects. This is a fantastic way to learn from experienced developers and give back to the community.\\n\\n**Stay Updated:**\\n\\n* **Research Papers:**  Keep up with the latest advancements by reading research papers on arXiv and other platforms.\\n* **Conferences and Blogs:** Attend AI conferences and follow influential blogs and researchers in the field.\\n\\n**Remember:**\\n\\n* **Start Small:** Break down complex problems into smaller, manageable tasks.\\n* **Experiment:**  Don't be afraid to try different approaches and see what works best.\\n* **Learn from Mistakes:**  AI development involves a lot of trial and error. Embrace the learning process.\\n\\nI'm excited to see what you create, Sachin!  Good luck with your generative AI journey!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 512, 'prompt_tokens': 56, 'total_tokens': 568, 'completion_time': 0.930909091, 'prompt_time': 0.003594929, 'queue_time': 0.2420543, 'total_time': 0.93450402}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--5908ec6a-4990-48e7-b569-ef40c8ddcdf9-0', usage_metadata={'input_tokens': 56, 'output_tokens': 512, 'total_tokens': 568})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:00.494548Z",
     "start_time": "2025-07-02T12:34:00.021889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#see this time it says i don't know about you name\n",
    "#basically the session id is a new one so no previous chat available it will be stored for the first time\n",
    "\n",
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],config=config\n",
    ")\n",
    "response"
   ],
   "id": "444ad6763fc803b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name. If you'd like to tell me, I'm happy to use it!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 13, 'total_tokens': 51, 'completion_time': 0.069090909, 'prompt_time': 0.00206003, 'queue_time': 0.241857872, 'total_time': 0.071150939}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--253518a3-6885-4b6a-b1e7-b95c4cf22a0a-0', usage_metadata={'input_tokens': 13, 'output_tokens': 38, 'total_tokens': 51})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:01.122798Z",
     "start_time": "2025-07-02T12:34:00.522027Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"ok tell me what is my name\")],config=config\n",
    ")\n",
    "response\n",
    "#see it remembers my name"
   ],
   "id": "11bc2d67546fc965",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Sachin Goyal. üòä  I remember it! \\n\\n\\nLet me know if you have any other questions about generative AI or anything else.  I'm here to help!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 583, 'total_tokens': 625, 'completion_time': 0.076363636, 'prompt_time': 0.02583528, 'queue_time': 0.24705448100000002, 'total_time': 0.102198916}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--b6b1c79d-2283-42fe-846e-f8c63556c4c0-0', usage_metadata={'input_tokens': 583, 'output_tokens': 42, 'total_tokens': 625})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:01.633645Z",
     "start_time": "2025-07-02T12:34:01.178764Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke([HumanMessage(content=\"My name is John\")],config=config)\n",
    "response"
   ],
   "id": "1fc4d4421a8fe1ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi John, it's nice to meet you!\\n\\nIs there anything I can help you with today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 63, 'total_tokens': 88, 'completion_time': 0.045454545, 'prompt_time': 0.00379868, 'queue_time': 0.243285469, 'total_time': 0.049253225}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--386b0b2d-c7f8-4ea2-823d-083311b60f87-0', usage_metadata={'input_tokens': 63, 'output_tokens': 25, 'total_tokens': 88})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:02.135059Z",
     "start_time": "2025-07-02T12:34:01.659628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"what is my name\")],config=config\n",
    ")\n",
    "response\n",
    "#this time remembers the name"
   ],
   "id": "e963eac8f340490e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='You said your name is John earlier.  \\n\\nWould you like me to call you something else? üòä  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 100, 'total_tokens': 125, 'completion_time': 0.045454545, 'prompt_time': 0.005276419, 'queue_time': 0.241617902, 'total_time': 0.050730964}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--3eabfd98-1bc6-484e-9a54-9b4f807008b1-0', usage_metadata={'input_tokens': 100, 'output_tokens': 25, 'total_tokens': 125})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Prompt templates\n",
    "Prompt Templates help to turn raw user information into a format that the LLM can work with. In this case, the raw user input is just a message, which we are passing to the LLM. Let's now make that a bit more complicated. First, let's add in a system message with some custom instructions (but still taking messages as input). Next, we'll add in more input besides just the messages."
   ],
   "id": "a9058ecd2efa6306"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:02.289895Z",
     "start_time": "2025-07-02T12:34:02.158392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "         (\"system\",\"You are a helpful assistant ,communicate with the user according\"),\n",
    "         MessagesPlaceholder(variable_name=\"messages\")\n",
    "     ]\n",
    " )\n",
    "chain=prompt|llm"
   ],
   "id": "58a08cfe4b5b62ed",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:02.850751Z",
     "start_time": "2025-07-02T12:34:02.336857Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({\"messages\":[HumanMessage(content=\"Hii ,My name is Sachin Goyal\")]})",
   "id": "966015b1490ad42a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Sachin Goyal, it's nice to meet you! üëã\\n\\nHow can I help you today? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 28, 'total_tokens': 55, 'completion_time': 0.049090909, 'prompt_time': 0.00232549, 'queue_time': 0.2408127, 'total_time': 0.051416399}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--65d3425f-f5d8-43e9-901f-f453ad7c7c91-0', usage_metadata={'input_tokens': 28, 'output_tokens': 27, 'total_tokens': 55})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:02.924831Z",
     "start_time": "2025-07-02T12:34:02.901875Z"
    }
   },
   "cell_type": "code",
   "source": "with_message_history=RunnableWithMessageHistory(chain,get_session_history)",
   "id": "c056b993b7602bac",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:03.483967Z",
     "start_time": "2025-07-02T12:34:03.014737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'message':[HumanMessage(content=\"My name is Sachin Goyal\")]},config=config\n",
    ")\n",
    "response"
   ],
   "id": "820708e8c6e9de60",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You're right!  I apologize for the mistake.  I'm still under development and learning to remember things accurately.  \\n\\nThanks for correcting me, Sachin.  \\n\\nHow can I help you further?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 650, 'total_tokens': 697, 'completion_time': 0.085454545, 'prompt_time': 0.02852218, 'queue_time': 0.24637427, 'total_time': 0.113976725}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--f4471881-9184-4ceb-b9a9-45099931d927-0', usage_metadata={'input_tokens': 650, 'output_tokens': 47, 'total_tokens': 697})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:04.096584Z",
     "start_time": "2025-07-02T12:34:03.532406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {'message':[HumanMessage(content=\"can you tell me what is my age and my fav hobby\")]},config=config\n",
    ")\n",
    "response"
   ],
   "id": "28b6a5cfc84f1ea5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have access to personal information about you like your age or favorite hobby. \\n\\nTo help me learn more about you, would you like to tell me your age and favorite hobby? üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 50, 'prompt_tokens': 717, 'total_tokens': 767, 'completion_time': 0.090909091, 'prompt_time': 0.030922791, 'queue_time': 0.24485893799999997, 'total_time': 0.121831882}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--af9750de-079c-4cad-96cf-9de12508e4e6-0', usage_metadata={'input_tokens': 717, 'output_tokens': 50, 'total_tokens': 767})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "What if we have multiple inputs to be taken in prompt\n",
    "--> then there is a change in with_message_history\n",
    "    we need to define a correct key to use to save chat to history"
   ],
   "id": "4007295494d07960"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:04.204382Z",
     "start_time": "2025-07-02T12:34:04.198276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "         (\"system\",\"You are a helpful assistant ,communicate with the user according in {language}\"),\n",
    "         MessagesPlaceholder(variable_name=\"messages\")\n",
    "     ]\n",
    " )\n",
    "chain=prompt|llm"
   ],
   "id": "15d1ce71bfe7fd48",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:04.703450Z",
     "start_time": "2025-07-02T12:34:04.254904Z"
    }
   },
   "cell_type": "code",
   "source": "chain.invoke({\"messages\":[HumanMessage(content=\"Hii ,My name is Sachin Goyal\")],\"language\":\"Hindi\"})",
   "id": "db736d7109c1b121",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§∏‡§ö‡§ø‡§® ‡§ó‡•ã‡§Ø‡§≤ ‡§ú‡•Ä! \\n\\n‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§Ü‡§™‡§∏‡•á ‡§Æ‡§ø‡§≤‡§®‡•á ‡§ï‡•Ä‡•§ ‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á? üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 30, 'total_tokens': 72, 'completion_time': 0.076363636, 'prompt_time': 0.00212683, 'queue_time': 0.244149009, 'total_time': 0.078490466}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--8e58cce0-3c7b-429e-bcbd-de2bc7a6f635-0', usage_metadata={'input_tokens': 30, 'output_tokens': 42, 'total_tokens': 72})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:04.744670Z",
     "start_time": "2025-07-02T12:34:04.735238Z"
    }
   },
   "cell_type": "code",
   "source": "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")",
   "id": "2ac3141b7d665bc3",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "whenever we reuse the older session for ex chat1 then it loads the old history and as we used english by default so now declaring any other language may not work for that and will print in english",
   "id": "d66878c48bff0549"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:05.309204Z",
     "start_time": "2025-07-02T12:34:04.821001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"can you tell me my name \")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "afef132f1e4c31e3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Sachin Goyal.  üòä  Is there anything else I can help you with today? \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 783, 'total_tokens': 808, 'completion_time': 0.045454545, 'prompt_time': 0.02787966, 'queue_time': 0.247722709, 'total_time': 0.073334205}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--d1e91ff6-e092-4b42-aad2-d50b5f1f4a10-0', usage_metadata={'input_tokens': 783, 'output_tokens': 25, 'total_tokens': 808})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:05.822064Z",
     "start_time": "2025-07-02T12:34:05.362075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"My name is Sachin Goyal\")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "996adf0a8342f763",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á Sachin Goyal ‡§ú‡•Ä! üëã\\n\\n‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡§æ ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å‡•§ ‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§ï‡•ã‡§à ‡§Æ‡§¶‡§¶ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å? üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 28, 'total_tokens': 68, 'completion_time': 0.072727273, 'prompt_time': 0.0021672, 'queue_time': 0.2424125, 'total_time': 0.074894473}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--71f108bc-4a6e-411e-b82a-37eba25c3d6d-0', usage_metadata={'input_tokens': 28, 'output_tokens': 40, 'total_tokens': 68})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:34:06.331279Z",
     "start_time": "2025-07-02T12:34:05.855345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"can you tell me my name \")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "bf5016f7dd752ae4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ Sachin Goyal ‡§π‡•à‡•§  üòÑ \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 83, 'total_tokens': 98, 'completion_time': 0.027272727, 'prompt_time': 0.005552549, 'queue_time': 0.24357124100000002, 'total_time': 0.032825276}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--16ee8e85-2892-4af6-ad6e-45c79b764b8d-0', usage_metadata={'input_tokens': 83, 'output_tokens': 15, 'total_tokens': 98})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Managing the Conversation History\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ],
   "id": "d91b0035c94c2dbb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:35:13.698040Z",
     "start_time": "2025-07-02T12:34:28.306493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy='last', # keep the msgs from last with tokens<=max_tokens\n",
    "    token_counter=llm,\n",
    "    allow_partial=False, #If a msg pushes total tokens over 45, it won‚Äôt partially include it instead, it will stop adding messages.\n",
    "    include_system=True, # as system guides the model what should it do so it must be present anyhow even after trimming msgs\n",
    "    start_on='human'  #look for the most recent HumanMessage and start including from there.\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ],
   "id": "bfd75dc6c1b11809",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cd834236846444f5aa88721ee47d61ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\GEN-AI\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Sachin Goyal\\.cache\\huggingface\\hub\\models--gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "641a82b0a21a4dbea161218f4744e0a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4ff0483dffe4a91b6cf4ef5e1d77065"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "667761b296f64e84b18578e3b4ffee3f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5b48516efed40f88b0f102e822b14ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:41:45.428545Z",
     "start_time": "2025-07-02T12:41:44.438455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(\n",
    "        RunnablePassthrough.assign(messages=itemgetter(\"messages\") |trimmer)\n",
    "       | prompt\n",
    "       | llm\n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\"messages\":messages+[HumanMessage(content=\"what ice cream do i like\")],\"language\":\"Hindi\"}\n",
    ")\n",
    "response"
   ],
   "id": "ad48d85361c6942d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"‡§Æ‡•Å‡§ù‡•á ‡§®‡§π‡•Ä‡§Ç ‡§™‡§§‡§æ ‡§ï‡§ø ‡§Ü‡§™‡§ï‡•ã ‡§ï‡•å‡§® ‡§∏‡§æ ‡§Ü‡§á‡§∏‡§ï‡•ç‡§∞‡•Ä‡§Æ ‡§™‡§∏‡§Ç‡§¶ ‡§π‡•à! ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§§‡§æ‡§ì, ‡§Ü‡§™‡§ï‡§æ ‡§™‡§∏‡§Ç‡§¶‡•Ä‡§¶‡§æ ‡§Ü‡§á‡§∏‡§ï‡•ç‡§∞‡•Ä‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?  üç¶üòä \\n\\n\\n(I don't know what your favorite ice cream is! Tell me, what's your favorite ice cream? üç¶üòä) \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 81, 'total_tokens': 153, 'completion_time': 0.130909091, 'prompt_time': 0.00413661, 'queue_time': 0.240947836, 'total_time': 0.135045701}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--9c5f8354-09ae-481a-897e-719f0390c667-0', usage_metadata={'input_tokens': 81, 'output_tokens': 72, 'total_tokens': 153})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:42:06.502642Z",
     "start_time": "2025-07-02T12:42:05.874128Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain=(\n",
    "        RunnablePassthrough.assign(messages=itemgetter(\"messages\") |trimmer)\n",
    "       | prompt\n",
    "       | llm\n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\"messages\":messages+[HumanMessage(content=\"what was my question regarding maths\")],\"language\":\"Hindi\"}\n",
    ")\n",
    "response"
   ],
   "id": "d65a7b8d2157dfe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§Ü‡§™‡§®‡•á ‡§Æ‡•Å‡§ù‡§∏‡•á 2 + 2 ‡§ï‡§æ ‡§ú‡§µ‡§æ‡§¨ ‡§™‡•Ç‡§õ‡§æ ‡§•‡§æ‡•§  \\n\\n\\n\\n(You asked me the answer to 2 + 2.)\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 81, 'total_tokens': 119, 'completion_time': 0.069090909, 'prompt_time': 0.00505106, 'queue_time': 0.24509043000000003, 'total_time': 0.074141969}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--47ccd9f4-abcc-4cfd-b3c6-5e4eff3a88ea-0', usage_metadata={'input_tokens': 81, 'output_tokens': 38, 'total_tokens': 119})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Wrapping with Message history",
   "id": "89bcb3d1f05ae272"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:44:34.798027Z",
     "start_time": "2025-07-02T12:44:34.608801Z"
    }
   },
   "cell_type": "code",
   "source": "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")",
   "id": "11ded0d3835f1412",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:45:46.663152Z",
     "start_time": "2025-07-02T12:45:45.595264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat6\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":messages+[HumanMessage(content=\"what is my name\")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "7c80d5d8804c3eef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•á ‡§®‡§æ‡§Æ ‡§ï‡•ã ‡§®‡§π‡•Ä‡§Ç ‡§ú‡§æ‡§®‡§§‡§æ‡•§ ‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à?  \\n \\n(I don't know your name. What's your name?)\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 79, 'total_tokens': 116, 'completion_time': 0.067272727, 'prompt_time': 0.00417959, 'queue_time': 0.24175738, 'total_time': 0.071452317}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--ece0cbdc-40ea-4e4b-a5c9-6ba4f56a5536-0', usage_metadata={'input_tokens': 79, 'output_tokens': 37, 'total_tokens': 116})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-02T12:47:37.294717Z",
     "start_time": "2025-07-02T12:47:36.631361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat6\"}}\n",
    "response=with_message_history.invoke(\n",
    "    {\"messages\":messages+[HumanMessage(content=\"My name is Sachin,can you tell me the meaning of this \")],\"language\":\"Hindi\"},config=config\n",
    ")\n",
    "response"
   ],
   "id": "727940c11440c2b6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sachin ‡§®‡§æ‡§Æ ‡§ï‡§æ ‡§Æ‡§§‡§≤‡§¨ ‡§π‡•à \"‡§∏‡§´‡§≤‡§§‡§æ\" ‡§Ø‡§æ \"‡§µ‡§ø‡§ú‡§Ø\"‡•§ ‡§Ø‡§π ‡§è‡§ï ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§∏‡•Å‡§Ç‡§¶‡§∞ ‡§î‡§∞ ‡§™‡•ç‡§∞‡§ö‡§≤‡§ø‡§§ ‡§®‡§æ‡§Æ ‡§π‡•à‡•§ üòä\\n\\n‡§ï‡•ç‡§Ø‡§æ ‡§Ü‡§™ ‡§ï‡•Å‡§õ ‡§î‡§∞ ‡§ú‡§æ‡§®‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 46, 'prompt_tokens': 72, 'total_tokens': 118, 'completion_time': 0.083636364, 'prompt_time': 0.003864509, 'queue_time': 0.24411575100000002, 'total_time': 0.087500873}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--15778390-bb81-4f22-a88c-64caee2f5a48-0', usage_metadata={'input_tokens': 72, 'output_tokens': 46, 'total_tokens': 118})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
